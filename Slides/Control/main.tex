\documentclass{beamer}

\input{settings.tex}


\title{Stabilizing Control}
\subtitle{Control Theory, Lecture 3}
\author{by Sergei Savin}
\centering
\date{\mydate}



\begin{document}
\maketitle


%\begin{frame}{Content}
%
%\begin{itemize}
%\item Stabilizing control
%\item Error dynamics
%\item Affine trajectory tracking
%\item Point-to-point control
%\item Pure state feedback
%\item Read more
%\end{itemize}
%
%\end{frame}



\begin{frame}{Changing stability}
% \framesubtitle{O}
\begin{flushleft}

Here are two LTIs:

\begin{equation}
    \dot{x} = 2 x
\end{equation}

\begin{equation}
    \dot{x} = 2 x + u
\end{equation}

First one is autonomous and unstable. Second one is not autonomous, and we won't know whether or not the solution converges to zero, until we know what $u$ is.

\bigskip

If we pick $u=0$, the result is an unstable equation. But we can also pick $u$ such that the resulting dynamics is stable, such as $u=-3x$:

\begin{equation}
    \dot{x} = 2 x + u = 2 x - 3x = -x
\end{equation}

\begin{block}{ }
So, we can use \emph{control input} $u$ to change stability of the system!
\end{block}


\end{flushleft}
\end{frame}





\begin{frame}{Stabilizing control}
% \framesubtitle{O}
\begin{flushleft}

\begin{definition}
The problem of finding control law $\bo{u}$ that make a certain solution $\bo{x}^*$ of dynamical system $\dot{\bo{x}} = \bo{f}(\bo{x}, \bo{u})$ stable is called \emph{stabilizing control problem}
\end{definition}

\bigskip

This is true for both linear and non-linear systems. But for linear systems we can get a lot more details about this problem, if we restrict our choice of control law.



\end{flushleft}
\end{frame}



\begin{frame}{Linear control}
\framesubtitle{Closed-loop system}
\begin{flushleft}

Consider an LTI system:

\begin{equation}
    \dot{\bo{x}} = \bo{A}\bo{x} + \bo{B}\bo{u}
\end{equation}

and let us chose \emph{control as a linear function of the state} $x$:

\begin{equation}
    \bo{u} = -\bo{K}\bo{x}
\end{equation}

We call matrix $\bo{K}$ \emph{control gain}. Thus, we know how the system is going to look when the control is applied:

\begin{equation}
    \dot{\bo{x}} = \bo{A}\bo{x} - \bo{B}\bo{K}\bo{x}
\end{equation}
\begin{equation}
\label{eq:closed_loop}
    \dot{\bo{x}} = (\bo{A} - \bo{B}\bo{K})\bo{x}
\end{equation}

Note that \eqref{eq:closed_loop} is an autonomous system. We call this a \emph{closed loop} system.

\end{flushleft}
\end{frame}



\begin{frame}{Linear control}
%\framesubtitle{Stability of the closed-loop system}
\begin{flushleft}

We can analyse stability of $\dot{\bo{x}} = (\bo{A} - \bo{B}\bo{K})\bo{x}$:

\begin{block}{Stability condition for LTI closed-loop system}
The real parts of the eigenvalues of the matrix $(\bo{A} - \bo{B}\bo{K})$ should be negative for asymptotic stability, or non-positive for stability in the sense of Lyapunov.
\end{block}

\begin{block}{Hurwitz matrix}
	If square matrix $\bo{M}$ has eigenvalues with strictly negative real parts, it is called Hurwitz. We will denote it as $\bo{M} \in \mathcal{H}$.
\end{block}

%\bigskip

So, all you need to do is to find such $\bo{K}$ that $(\bo{A} - \bo{B}\bo{K})$ is Hurwitz, and you made a an asymptotically stable closed-loop system!

\end{flushleft}
\end{frame}




\begin{frame}{Scalar case}
	%\framesubtitle{Stability of the closed-loop system}
	\begin{flushleft}
		
		Let us consider the following system:
		
		\begin{equation}
			\dot x = a x + b u
		\end{equation}
	
		we can choose the following linear control law: $u = - k x$. The close loop system for this example is:
		
		\begin{equation}
			\dot x = (a- bk) x
		\end{equation}		
	
		The solution to the closed-loop system is:
		
		\begin{equation}
			x(t) =  x_0 e^{(a- bk)t}
		\end{equation}		
		
		As long as $a- bk < 0$, the solution is converging to zero. Since we can pick $k$, we can choose it so that $a- bk = -q$, where $q$ is a positive number. Then, we pick $k = \frac{q+a}{b}$, giving us stable system with eigenvalue $-q$.
		
	\end{flushleft}
\end{frame}



\begin{frame}{Multivariable case}
	%\framesubtitle{Stability of the closed-loop system}
	\begin{flushleft}
		
		Let us consider the following system:
		%
		\begin{equation}
			\begin{bmatrix}
				\dot x_1 \\ \dot x_2
			\end{bmatrix} 
		= 
		\begin{bmatrix}
			a_{11} & a_{12} \\ 0 & a_{22}
		\end{bmatrix}
		\begin{bmatrix}
			x_1 \\ x_2
		\end{bmatrix} 
	+ 
		\begin{bmatrix}
			b \\ 0
		\end{bmatrix}
		u
		\end{equation}
		
		With control law:
		%
		\begin{equation}
			u
			= 
			-
			\begin{bmatrix}
				k_1 & k_2
			\end{bmatrix}
			\begin{bmatrix}
				x_1 \\ x_2
			\end{bmatrix} 
		\end{equation}
		
		Close-loop system is:
		%
		\begin{equation}
			\begin{bmatrix}
				\dot x_1 \\ \dot x_2
			\end{bmatrix} 
			= 
			\begin{bmatrix}
				a_{11}-b k_1 & a_{12}-b k_2 \\ 0 & a_{22}
			\end{bmatrix}
			\begin{bmatrix}
				x_1 \\ x_2
			\end{bmatrix} 
		\end{equation}
		
		The eigenvalues of the closed-loop system are $a_{11}-b k_1$ and $a_{22}$.  The second eigenvalue cannot be influenced by the choice of control gains. If $a_{22} < 0$, we need to pick $k_1$, such as  $a_{11}-b k_1 = -q$, where $q$ is a positive number: $k_1 = \frac{q + a_{11}}{b}$.
		
	\end{flushleft}
\end{frame}





\begin{frame}{Spring-mass-damper, 1}
	%\framesubtitle{Stability of the closed-loop system}
	\begin{flushleft}
		
		Let us consider a spring-mass-damper:
		%
		\begin{equation}
			\ddot y + \mu \dot y + c y = 0
		\end{equation}
		
		The eq. can be re-written in state-space form with a change of variables $x_1 = y$ and $x_2 = \dot y$:
		%
		\begin{equation}
			\begin{bmatrix}
				\dot x_1 \\ \dot x_2
			\end{bmatrix} 
			= 
			\begin{bmatrix}
				0 & 1 \\ - c & -\mu
			\end{bmatrix}
			\begin{bmatrix}
				x_1 \\ x_2
			\end{bmatrix}
		\end{equation}
		
		
		It is easy compute eigenvalues of a 2 by 2 matrix, using its determinant $\text{det}$ and trace $\text{tr}$:
		%
		\begin{equation}
			\lambda = \frac{\text{tr} \pm \sqrt{\text{tr}^2 - 4 \text{det}}}{2} 
		\end{equation}
		
		Here $\text{det} = c$ and $\text{tr} = -\mu$:
		%
		\begin{equation}
			\lambda = \frac{-\mu \pm \sqrt{\mu^2 - 4 c}}{2} 
		\end{equation}
		
	\end{flushleft}
\end{frame}


\begin{frame}{Spring-mass-damper, 2}
	% \framesubtitle{O}
	\begin{flushleft}
		
		Let us analyze eigenvalues $\lambda = \frac{-\mu \pm \sqrt{\mu^2 - 4 c} }{2}$. We can see that if \textcolor{mydarkgreen}{$\mu > 0$} and \textcolor{mydarkgreen}{$ c > 0$}, there are only two scenarios: 
		
		\begin{enumerate}
			\item $\mu^2 - 4c \geq 0$, in which case $\sqrt{\mu^2 - 4c} \leq \mu$, the eigenvalues are purely real and \textcolor{mydarkgreen}{negative}.
			\item $\mu^2 - 4c < 0$, in which case $\sqrt{\mu^2 - 4c}$ is a purely imaginary number, the eigenvalues are complex with \textcolor{mydarkgreen}{negative real parts}.
		\end{enumerate}
		
		If $\mu > 0$ and \textcolor{myblue}{$c = 0$}, then $\lambda_1 = -\mu$, $\lambda_2 = 0$, hence the system is \textcolor{myblue}{marginally stable}.
		
		If \textcolor{myblue}{$\mu = 0$} and $c > 0$, then $\lambda = \pm i \sqrt{c}$, hence the system is \textcolor{myblue}{marginally stable}.
		
	\end{flushleft}
\end{frame}



\begin{frame}{Spring-mass-damper, 3}
	\begin{flushleft}
		
		
		If $\mu \geq 0$ and \textcolor{red}{$c < 0$}, then $\sqrt{\mu^2 - 4c} \geq \mu$, and eigenvalues are purely real and one of them is \textcolor{red}{positive}, the system is unstable. If $\mu < 0$ and $c < 0$ at least one of the eigenvalues is still positive.
		
		\bigskip
		
		If \textcolor{red}{$\mu < 0$} and $c \geq 0$, then again there are only two scenarios: 
		
		\begin{enumerate}
			\item $\mu^2 - 4c \geq 0$, in which case $\sqrt{\mu^2 - 4c} \leq \mu$, the eigenvalues are purely real and \textcolor{red}{positive}.
			\item $\mu^2 - 4c < 0$, in which case $\sqrt{\mu^2 - 4c}$ is a purely imaginary number, the eigenvalues are complex with \textcolor{red}{positive real parts}.
		\end{enumerate}
		
		\begin{definition}
			Iff $\mu \geq 0$ and $c \geq 0$ the system $\ddot y + \mu \dot y + c y = 0$ is stable.
		\end{definition}
		
	\end{flushleft}
\end{frame}



\begin{frame}{PD control, 1}
	\begin{flushleft}
		
		Let us consider a spring-mass-damper:
		%
		\begin{equation}
			\ddot y + \mu \dot y + c y = u
		\end{equation}
		
		We can propose the feedback control in the form:
		%
		\begin{equation}
			u = -k_d \dot y  -k_p y 
		\end{equation}
		%
		this is called a \emph{proportional-differential controler}, often shortened as \emph{PD controller}; $k_d$ is a differential coefficient and $k_p$ is a proportional coefficient. The closed-loop system is:
		%
		\begin{align}
			\ddot y + (\mu + k_d) \dot y + (c+k_p) y = 0
		\end{align}
		
		The eigenvalues are:
		%
		\begin{align}
			d &= \sqrt{(\mu + k_d)^2 - 4 (c+k_p)}
			\\
			\lambda &= \frac{-(\mu + k_d) \pm d}{2} 
		\end{align}
		
		
	\end{flushleft}
\end{frame}



\begin{frame}{PD control, 2}
	\begin{flushleft}
		
		Given $c = 40$ and $\mu = 8$, assume that we want the closed-loop system to have eigenvalues $\lambda_1 = -4$ and $\lambda_2 = -20$.
		%
		\begin{align}
			16 = \lambda_1 - \lambda_2= \frac{-(\mu + k_d) +d}{2} - \frac{-(\mu + k_d) - d}{2}  = d
		\end{align}
		%
		It follows that:
		%
		\begin{align}
			-4 = \lambda_1 = \frac{-(\mu + k_d) + 16}{2}
			\\
			-(\mu + k_d) + 16 = -8
			\\
			k_p  = 16
		\end{align}
		
		
		Also we can write:
		%
		\begin{align}
			d = \sqrt{(\mu + k_d)^2 - 4 (c+k_p)}
			\\
			16^2 = 24^2 - 4 (40 + k_p)
			\\
			k_p = 320 / 4 - 40 = 40
		\end{align}
		
		
	\end{flushleft}
\end{frame}







\begin{frame}{Pole-placement}
	\begin{flushleft}
		
		The method of finding control gains in such a way that the closed-loop system has desired eigenvalues is called \emph{pole placement}.
		
		\bigskip
		
		As the earlier example illustrated, it is not easy to do manually. However, there is software that finds such control gains automatically.
		
		\bigskip
		
		In MATLAB there is a function \texttt{K = place(A,B,p)}, where \texttt{p} are the desired eigenvalues of \texttt{(A-B*K)}.
		
		
	\end{flushleft}
\end{frame}










\begin{frame}{Trajectory tracking, 1}
	\begin{flushleft}
		
		Let the function $\bo{x}^* = \bo{x}^*(t)$ and control $\bo{u}^* = \bo{u}^*(t)$ be a solution to the system $\dot{\bo{x}} = \bo{A}\bo{x} + \bo{B}\bo{u}$, meaning:
		%
		\begin{equation}
			\dot{\bo{x}}^* = \bo{A}\bo{x}^* + \bo{B}\bo{u}^*
		\end{equation}
	
		We call $\bo{x}^*(t)$ a \emph{reference} or \emph{reference input} and $\bo{u}^*(t)$ a \emph{feed-forward control}.
		
		\bigskip
		
		We can try to find control law that would stabilize this reference trajectory. We begin by finding the difference between $\dot{\bo{x}}^*$ and $\dot{\bo{x}}$:
		%
		\begin{equation}
			\dot{\bo{x}}^* - \dot{\bo{x}}= \bo{A}(\bo{x}^*-\bo{x}) + \bo{B}(\bo{u}^*-\bo{u})
		\end{equation}
		
		We define new variables: $\bo{e} = \bo{x}^* - \bo{x}$ and $\bo{v} = \bo{u}^* - \bo{u}$:
		%
		\begin{equation}
			\dot{\bo{e}} = \bo{A}\bo{e} + \bo{B}\bo{v}
		\end{equation}
		
	\end{flushleft}
\end{frame}



\begin{frame}{Trajectory tracking, 2}
	%\framesubtitle{Stability of the closed-loop system}
	\begin{flushleft}
		
		We call $\bo{e}$ \emph{control error} and the equation $\dot{\bo{e}} = \bo{A}\bo{e} + \bo{B}\bo{v}$ is \emph{error dynamics}.
		
		\bigskip
		
		With that we are back to the familiar problem - find control law $\bo{v} = -\bo{K}\bo{e}$ that makes closed-loop system stable:
		%
		\begin{equation}
			\dot{\bo{e}} = (\bo{A} - \bo{B}\bo{K}) \bo{e}
		\end{equation}
		
		In the original variables it is:
		%
		\begin{equation}
			\bo{u} = \bo{K}(\bo{x}^* - \bo{x}) + \bo{u}^*
		\end{equation}
		
	\end{flushleft}
\end{frame}




\begin{frame}{Point-to-point control}
	%\framesubtitle{Stability of the closed-loop system}
	\begin{flushleft}
		
		Consider the system $\dot{\bo{x}} = \bo{A}\bo{x} + \bo{B}\bo{u}$ and the reference input $\bo{x}^* = \text{const}$ and feed-forward control $\bo{u}^*= \text{const}$. This implies:
		
		\begin{equation}
			\bo{A}\bo{x}^* + \bo{B}\bo{u}^* = 0
		\end{equation}		
		
		We can try to find control law that would stabilize this reference trajectory. The error dynamics and the stabilizing control law are the same as in the previous case. But this time, we can find $\bo{u}^*$ if it is not provided:
		
		\begin{equation}
			 \bo{u}^* = -\bo{B}^+\bo{A}\bo{x}^*
		\end{equation}				
		
	\end{flushleft}
\end{frame}



\begin{frame}{New input}
	%\framesubtitle{Stability of the closed-loop system}
	\begin{flushleft}
		
		Consider the system $\dot{\bo{x}} = \bo{A}\bo{x} + \bo{B}\bo{u}$ and control law $\bo{u} = \bo{K}(\bo{x}^*(t) - \bo{x}) + \bo{u}^*(t)$. We can find the expression for the resulting system:
		
		\begin{align}
			\dot{\bo{x}} = \bo{A}\bo{x} + \bo{B}\bo{K}(\bo{x}^*(t) - \bo{x}) + \bo{B}\bo{u}^*(t) \\
			\dot{\bo{x}} = (\bo{A}- \bo{B}\bo{K})\bo{x} +\bo{B}\bo{K}\bo{x}^*(t) + \bo{B}\bo{u}^*(t)
		\end{align}		
		
		Assuming that $\bo{u}^*(t) = 0$ gives us a simplified system:
		
		\begin{align}
			\dot{\bo{x}} =  (\bo{A}- \bo{B}\bo{K})\bo{x} +\bo{B}\bo{K}\bo{x}^*(t)
		\end{align}				
		
		Here we can see that $\bo{x}^*(t)$ acts as a new input, and it makes sense to discuss how the system reacts to various inputs.
		
	\end{flushleft}
\end{frame}




\begin{frame}{Where are we}
	
	% TODO: \usepackage{graphicx} required
	\begin{figure}
		\centering
		\includegraphics[width=1.00\linewidth]{"Scheme colors"}
	\end{figure}
	

\end{frame}





\begin{frame}{Literature}

\begin{itemize}
	
	
	\item Nise, N.S. Control systems engineering. John Wiley \& Sons. (4.5 The General Second-Order System)	
	
	\item \bref{https://apmonitor.com/pdc/index.php/Main/ModelSimulation}{Dynamic Simulation in Python}
\end{itemize}
\end{frame}




\myqrframe

\end{document}
