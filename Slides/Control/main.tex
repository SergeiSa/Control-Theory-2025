\documentclass{beamer}

\input{settings.tex}


\title{Stabilizing Control}
\subtitle{Control Theory, Lecture 3}
\author{by Sergei Savin}
\centering
\date{\mydate}



\begin{document}
\maketitle


%\begin{frame}{Content}
%
%\begin{itemize}
%\item Stabilizing control
%\item Error dynamics
%\item Affine trajectory tracking
%\item Point-to-point control
%\item Pure state feedback
%\item Read more
%\end{itemize}
%
%\end{frame}



\begin{frame}{Changing stability}
% \framesubtitle{O}
\begin{flushleft}

Here are two LTIs:

\begin{equation}
    \dot{x} = 2 x
\end{equation}

\begin{equation}
    \dot{x} = 2 x + u
\end{equation}

First one is autonomous and unstable. Second one is not autonomous, and we won't know whether or not the solution converges to zero, until we know what $u$ is.

\bigskip

If we pick $u=0$, the result is an unstable equation. But we can also pick $u$ such that the resulting dynamics is stable, such as $u=-3x$:

\begin{equation}
    \dot{x} = 2 x + u = 2 x - 3x = -x
\end{equation}

\begin{block}{ }
So, we can use \emph{control input} $u$ to change stability of the system!
\end{block}


\end{flushleft}
\end{frame}





\begin{frame}{Stabilizing control}
% \framesubtitle{O}
\begin{flushleft}

\begin{definition}
The problem of finding control law $\bo{u}$ that make a certain solution $\bo{x}^*$ of dynamical system $\dot{\bo{x}} = \bo{f}(\bo{x}, \bo{u})$ stable is called \emph{stabilizing control problem}
\end{definition}

\bigskip

This is true for both linear and non-linear systems. But for linear systems we can get a lot more details about this problem, if we restrict our choice of control law.



\end{flushleft}
\end{frame}



\begin{frame}{Linear control}
\framesubtitle{Closed-loop system}
\begin{flushleft}

Consider an LTI system:

\begin{equation}
    \dot{\bo{x}} = \bo{A}\bo{x} + \bo{B}\bo{u}
\end{equation}

and let us chose \emph{control as a linear function of the state} $x$:

\begin{equation}
    \bo{u} = -\bo{K}\bo{x}
\end{equation}

We call matrix $\bo{K}$ \emph{control gain}. Thus, we know how the system is going to look when the control is applied:

\begin{equation}
    \dot{\bo{x}} = \bo{A}\bo{x} - \bo{B}\bo{K}\bo{x}
\end{equation}
\begin{equation}
\label{eq:closed_loop}
    \dot{\bo{x}} = (\bo{A} - \bo{B}\bo{K})\bo{x}
\end{equation}

Note that \eqref{eq:closed_loop} is an autonomous system. We call this a \emph{closed loop} system.

\end{flushleft}
\end{frame}



\begin{frame}{Linear control}
%\framesubtitle{Stability of the closed-loop system}
\begin{flushleft}

We can analyse stability of $\dot{\bo{x}} = (\bo{A} - \bo{B}\bo{K})\bo{x}$:

\begin{block}{Stability condition for LTI closed-loop system}
The real parts of the eigenvalues of the matrix $(\bo{A} - \bo{B}\bo{K})$ should be negative for asymptotic stability, or non-positive for stability in the sense of Lyapunov.
\end{block}

\begin{block}{Hurwitz matrix}
	If square matrix $\bo{M}$ has eigenvalues with strictly negative real parts, it is called Hurwitz. We will denote it as $\bo{M} \in \mathcal{H}$.
\end{block}

%\bigskip

So, all you need to do is to find such $\bo{K}$ that $(\bo{A} - \bo{B}\bo{K})$ is Hurwitz, and you made a an asymptotically stable closed-loop system!

\end{flushleft}
\end{frame}




\begin{frame}{Scalar case}
	%\framesubtitle{Stability of the closed-loop system}
	\begin{flushleft}
		
		Let us consider the following system:
		
		\begin{equation}
			\dot x = a x + b u
		\end{equation}
	
		we can choose the following linear control law: $u = - k x$. The close loop system for this example is:
		
		\begin{equation}
			\dot x = (a- bk) x
		\end{equation}		
	
		The solution to the closed-loop system is:
		
		\begin{equation}
			x(t) =  x_0 e^{(a- bk)t}
		\end{equation}		
		
		As long as $a- bk < 0$, the solution is converging to zero. Since we can pick $k$, we can choose it so that $a- bk = -q$, where $q$ is a positive number. Then, we pick $k = \frac{q+a}{b}$, giving us stable system with eigenvalue $-q$.
		
	\end{flushleft}
\end{frame}



\begin{frame}{Multivariable case}
	%\framesubtitle{Stability of the closed-loop system}
	\begin{flushleft}
		
		Let us consider the following system:
		%
		\begin{equation}
			\begin{bmatrix}
				\dot x_1 \\ \dot x_2
			\end{bmatrix} 
		= 
		\begin{bmatrix}
			a_{11} & a_{12} \\ 0 & a_{22}
		\end{bmatrix}
		\begin{bmatrix}
			x_1 \\ x_2
		\end{bmatrix} 
	+ 
		\begin{bmatrix}
			b \\ 0
		\end{bmatrix}
		u
		\end{equation}
		
		With control law:
		%
		\begin{equation}
			u
			= 
			-
			\begin{bmatrix}
				k_1 & k_2
			\end{bmatrix}
			\begin{bmatrix}
				x_1 \\ x_2
			\end{bmatrix} 
		\end{equation}
		
		Close-loop system is:
		%
		\begin{equation}
			\begin{bmatrix}
				\dot x_1 \\ \dot x_2
			\end{bmatrix} 
			= 
			\begin{bmatrix}
				a_{11}-b k_1 & a_{12}-b k_2 \\ 0 & a_{22}
			\end{bmatrix}
			\begin{bmatrix}
				x_1 \\ x_2
			\end{bmatrix} 
		\end{equation}
		
		The eigenvalues of the closed-loop system are $a_{11}-b k_1$ and $a_{22}$.  The second eigenvalue cannot be influenced by the choice of control gains. If $a_{22} < 0$, we need to pick $k_1$, such as  $a_{11}-b k_1 = -q$, where $q$ is a positive number: $k_1 = \frac{q + a_{11}}{b}$.
		
	\end{flushleft}
\end{frame}





\begin{frame}{Spring-mass-dumper, 1}
	%\framesubtitle{Stability of the closed-loop system}
	\begin{flushleft}
		
		Let us consider a spring-mass-dumper:
		%
		\begin{equation}
			\ddot y + \mu \dot y + c y = u
		\end{equation}
		
		We can propose the feedback control in the form:
		%
		\begin{equation}
			u = -k_d \dot y  -k_p y 
		\end{equation}
		%
		this is called a \emph{proportional-differential controler}, often shortened as \emph{PD controller}; $k_d$ is a differential coefficient and $k_p$ is a proportional coefficient. The closed-loop system is:
		%
		\begin{equation}
			\ddot y + (\mu + k_d) \dot y + (c+k_p) y = 0
		\end{equation}
		
		
		In state-space form it is:
		%
		\begin{equation}
			\begin{bmatrix}
				\dot x_1 \\ \dot x_2
			\end{bmatrix} 
			= 
			\begin{bmatrix}
				0 & 1 \\ -(\mu + k_d) & -(c+k_p)
			\end{bmatrix}
			\begin{bmatrix}
				x_1 \\ x_2
			\end{bmatrix}
		\end{equation}
		
		
		
	\end{flushleft}
\end{frame}




\begin{frame}{Spring-mass-dumper, 2}
	%\framesubtitle{Stability of the closed-loop system}
	\begin{flushleft}
		
		The stability of the system depends on the eigenvalues of the state matrix of the closed-loop system:
		%
		\begin{equation}
			\begin{bmatrix}
				0 & 1 \\ -(\mu + k_d) & -(c+k_p)
			\end{bmatrix}
		\end{equation}
		
		It is easy compute eigenvalues of a 2 by 2 matrix, using its determinant $\text{det}$ and trace $\text{tr}$:
		%
		\begin{equation}
			\lambda = \frac{1}{2} \left( \text{tr} \pm \sqrt{\text{tr}^2 - 4 \text{det}} \right)
		\end{equation}
		
		In this case $\text{det} = (\mu + k_d)$ and $\text{tr} = - (c+k_p)$.
		%
		\begin{equation}
			\lambda = \frac{1}{2} \left( - (c+k_p) \pm \sqrt{(c+k_p)^2 - 4 (\mu + k_d)} \right)
		\end{equation}
		
		
	\end{flushleft}
\end{frame}



\begin{frame}{Spring-mass-dumper, 3}
	%\framesubtitle{Stability of the closed-loop system}
	\begin{flushleft}
		
		
		We define $d = \sqrt{(c+k_p)^2 - 4 (\mu + k_d)}$:
		
		\begin{equation}
			\lambda = \frac{1}{2} \left( - (c+k_p) \pm d \right)
		\end{equation}
		
		
\begin{itemize}
	\item 
	If \textcolor{red}{$\mu + k_d < 0$} then $(c+k_p)^2 - 4 (\mu + k_d) > 0$ and $d > (c+k_p)$, so one of the eigenvalues is \textcolor{red}{positive}.
	
	\item 
	If \textcolor{myblue}{$\mu + k_d = 0$} then $d = (c+k_p)$, so one of the eigenvalues is \textcolor{myblue}{zero}.
	
	\item 
	If \textcolor{mydarkgreen}{$\mu + k_d > 0$} then it is either complex or $0 < d < (c+k_p)$ if it is real;
	
	\begin{itemize}
		\item if \textcolor{red}{$c+k_p < 0$} then one of the eigenvalues is \textcolor{red}{positive}.
		
		\item if \textcolor{myblue}{$c+k_p = 0$} then $\lambda = \pm  i \sqrt{ (\mu + k_d)}$
		
		\item if \textcolor{mydarkgreen}{$c+k_p > 0$} then both eigenvalues are have \textcolor{mydarkgreen}{negative} real parts.
	\end{itemize}
	
\end{itemize}
		
		
		
	\end{flushleft}
\end{frame}



\begin{frame}{Spring-mass-dumper, 4}
	%\framesubtitle{Stability of the closed-loop system}
	\begin{flushleft}
		
		
		\begin{equation}
			\ddot y + (\mu + k_d) \dot y + (c+k_p) y = 0
		\end{equation}
		
		\begin{itemize}
			\item 
			Note that the \textcolor{mydarkgreen}{asymptotic stability} is achieved when $\mu + k_d > 0$ and $c+k_p > 0$.
			
			\item 
			If $\mu + k_d \geq 0$ and $c+k_p \geq 0$ then the system is \textcolor{myblue}{marginally stable}.
			
			\item 
			if either $\mu + k_d < 0$ or $c+k_p < 0$ the system is \textcolor{red}{unstable}.
		\end{itemize}
		
		
	\end{flushleft}
\end{frame}



\begin{frame}{Spring-mass-dumper, 5}
	%\framesubtitle{Stability of the closed-loop system}
	\begin{flushleft}
		
		Given $c = 8$ and $\mu = 40$, assume that we want the closed-loop system to have eigenvalues $\lambda_1 = -4$ and $\lambda_2 = -20$.
		%
		\begin{align}
			16 = \lambda_1 - \lambda_2= \frac{1}{2} ( - (c+k_p) + d ) -  \frac{1}{2} ( - (c+k_p) - d ) = d
		\end{align}
		%
		It follows that:
		%
		\begin{align}
			-4 = \lambda_1 = \frac{1}{2} ( - (c+k_p) + 16)
			\\
			- (c+k_p) + 16 = -8
			\\
			k_p  = 16
		\end{align}
		
		
		Also we can write:
		%
		\begin{align}
			d = \sqrt{(c+k_p)^2 - 4 (\mu + k_d)}
			\\
			16^2 = 24^2 - 4 (40 + k_d)
			\\
			k_d = 320 / 4 - 40 = 40
		\end{align}
		
		
	\end{flushleft}
\end{frame}




\begin{frame}{Pole-placement}
	%\framesubtitle{Stability of the closed-loop system}
	\begin{flushleft}
		
		The method of finding control gains in such a way that the closed-loop system has desired eigenvalues is called \emph{pole placement}.
		
		\bigskip
		
		As the earlier example illustrated, it is not easy to do manually. However, there is software that finds such control gains automatically.
		
		\bigskip
		
		In MATLAB there is a function \texttt{K = place(A,B,p)}, where \texttt{p} is teh desired aigenvalues of \texttt{(A-B*K)}.
		
		
	\end{flushleft}
\end{frame}










\begin{frame}{Trajectory tracking (1)}
	%\framesubtitle{Stability of the closed-loop system}
	\begin{flushleft}
		
		Let the function $\bo{x}^* = \bo{x}^*(t)$ and control $\bo{u}^* = \bo{u}^*(t)$ be a solution to the system $\dot{\bo{x}} = \bo{A}\bo{x} + \bo{B}\bo{u}$, meaning:
		%
		\begin{equation}
			\dot{\bo{x}}^* = \bo{A}\bo{x}^* + \bo{B}\bo{u}^*
		\end{equation}
	
		We call $\bo{x}^*(t)$ a \emph{reference} or \emph{reference input} and $\bo{u}^*(t)$ a \emph{feed-forward control}.
		
		\bigskip
		
		We can try to find control law that would stabilize this reference trajectory. We begin by finding the difference between $\dot{\bo{x}}^*$ and $\dot{\bo{x}}$:
		%
		\begin{equation}
			\dot{\bo{x}}^* - \dot{\bo{x}}= \bo{A}(\bo{x}^*-\bo{x}) + \bo{B}(\bo{u}^*-\bo{u})
		\end{equation}
		
		We define new variables: $\bo{e} = \bo{x}^* - \bo{x}$ and $\bo{v} = \bo{u}^* - \bo{u}$:
		%
		\begin{equation}
			\dot{\bo{e}} = \bo{A}\bo{e} + \bo{B}\bo{v}
		\end{equation}
		
	\end{flushleft}
\end{frame}



\begin{frame}{Trajectory tracking (2)}
	%\framesubtitle{Stability of the closed-loop system}
	\begin{flushleft}
		
		We call $\bo{e}$ \emph{control error} and the equation $\dot{\bo{e}} = \bo{A}\bo{e} + \bo{B}\bo{v}$ is \emph{error dynamics}.
		
		\bigskip
		
		With that we are back to the familiar problem - find control law $\bo{v} = -\bo{K}\bo{e}$ that makes closed-loop system stable:
		%
		\begin{equation}
			\dot{\bo{e}} = (\bo{A} - \bo{B}\bo{K}) \bo{e}
		\end{equation}
		
		In the original variables it is:
		%
		\begin{equation}
			\bo{u} = \bo{K}(\bo{x}^* - \bo{x}) + \bo{u}^*
		\end{equation}
		
	\end{flushleft}
\end{frame}




\begin{frame}{Point-to-point control}
	%\framesubtitle{Stability of the closed-loop system}
	\begin{flushleft}
		
		Consider the system $\dot{\bo{x}} = \bo{A}\bo{x} + \bo{B}\bo{u}$ and the reference input $\bo{x}^* = \text{const}$ and feed-forward control $\bo{u}^*= \text{const}$. This implies:
		
		\begin{equation}
			\bo{A}\bo{x}^* + \bo{B}\bo{u}^* = 0
		\end{equation}		
		
		We can try to find control law that would stabilize this reference trajectory. The error dynamics and the stabilizing control law are the same as in the previous case. But this time, we can find $\bo{u}^*$ if it is not provided:
		
		\begin{equation}
			 \bo{u}^* = -\bo{B}^+\bo{A}\bo{x}^*
		\end{equation}				
		
	\end{flushleft}
\end{frame}



\begin{frame}{New input}
	%\framesubtitle{Stability of the closed-loop system}
	\begin{flushleft}
		
		Consider the system $\dot{\bo{x}} = \bo{A}\bo{x} + \bo{B}\bo{u}$ and control law $\bo{u} = \bo{K}(\bo{x}^*(t) - \bo{x}) + \bo{u}^*(t)$. We can find the expression for the resulting system:
		
		\begin{align}
			\dot{\bo{x}} = \bo{A}\bo{x} + \bo{B}\bo{K}(\bo{x}^*(t) - \bo{x}) + \bo{B}\bo{u}^*(t) \\
			\dot{\bo{x}} = (\bo{A}- \bo{B}\bo{K})\bo{x} +\bo{B}\bo{K}\bo{x}^*(t) + \bo{B}\bo{u}^*(t)
		\end{align}		
		
		Assuming that $\bo{u}^*(t) = 0$ gives us a simplified system:
		
		\begin{align}
			\dot{\bo{x}} =  (\bo{A}- \bo{B}\bo{K})\bo{x} +\bo{B}\bo{K}\bo{x}^*(t)
		\end{align}				
		
		Here we can see that $\bo{x}^*(t)$ acts as a new input, and it makes sense to discuss how the system reacts to various inputs.
		
	\end{flushleft}
\end{frame}



\begin{frame}{Read more}

\begin{itemize}
\item Richard M. Murray Control and Dynamical Systems California Institute of Technology \bref{http://www.cds.caltech.edu/~murray/books/AM08/pdf/obc-trajgen_03Jan10.pdf}{Optimization-Based Control}
\item \bref{https://apmonitor.com/pdc/index.php/Main/ModelSimulation}{Dynamic Simulation in Python}
\end{itemize}
\end{frame}




\myqrframe

\end{document}
